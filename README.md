# dask-taxi-fare-prediction
A scalable machine learning pipeline for predicting NYC taxi fares using Dask for big data processing and modeling. This project analyzes 12+ million taxi trips from March 2016 to build an accurate fare prediction model that explains 93.66% of fare variance while efficiently handling large-scale datasets.

# Описание проекта
Этот проект представляет собой комплексный анализ большого датасета поездок такси Нью-Йорка (NYC Yellow Taxi Trip Data) с использованием библиотеки Dask для обработки данных, превышающих объем оперативной памяти. Проект включает полный цикл анализа данных: от очистки и предварительной обработки до построения и оценки модели машинного обучения для предсказания стоимости поездок.

[**Используется официальный датасет такси Нью-Йорка с платформы Kaggle:**](https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data?spm=a2ty_o01.29997173.0.0.28b85171toFl1E&select=yellow_tripdata_2016-03.csv)

# Запуск
В Google Colab (рекомендуется):
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/VeronikaKolimova/dask-taxi-fare-prediction/blob/main/L_04_Dask_ML.ipynb)

# Основные цели
- Анализ более 12 миллионов поездок такси за март 2016 года
- Обнаружение и обработка выбросов в данных
- Исследование взаимосвязей между признаками (расстояние, время, скорость, час суток)
- Построение модели линейной регрессии для предсказания стоимости поездок
- Оценка качества модели и интерпретация результатов
- Визуализация ключевых закономерностей и результатов моделирования

# Технологический стек
**Основные библиотеки**
Dask — параллельные вычисления и обработка данных за пределами RAM
dask.dataframe — обработка табличных данных
dask-ml — машинное обучение с поддержкой Dask
NumPy/Pandas — числовые вычисления и работа с данными
Scikit-learn — метрики оценки качества моделей
Matplotlib/Seaborn — визуализация данных
Joblib — сохранение моделей и препроцессоров

# Архитектура решения
┌─────────────────────────────────────────────────────────────┐
│  1. Загрузка данных через Dask DataFrame                     │
│     (ленивая загрузка без полной загрузки в память)         │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│  2. Предварительная обработка:                              │
│     • Фильтрация выбросов (дистанция, стоимость, время)     │
│     • Расчет скорости движения                              │
│     • Извлечение часа суток из временных меток              │
│     • Удаление некорректных записей                         │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│  3. Инженерия признаков и подготовка данных:                │
│     • Масштабирование признаков (StandardScaler)            │
│     • Разделение на обучающую/тестовую выборки              │
│     • Параллельная обработка через Dask                     │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│  4. Обучение модели:                                        │
│     • Линейная регрессия (Dask-ML)                          │
│     • Распределенное обучение на фрагментах данных          │
│     • Время обучения: ~45 минут для 12 млн записей          │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│  5. Оценка и анализ:                                        │
│     • Метрики качества (R²=0.9366, RMSE=$2.64, MAE=$0.71)   │
│     • Анализ ошибок и выбросов                              │
│     • Интерпретация коэффициентов модели                    │
│     • Статистика по часам суток                             │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│  6. Сохранение результатов:                                 │
│     • Модель (joblib)                                       │
│     • Скалер для нормализации                               │
│     • Результаты в JSON и CSV                               │
│     • Визуализации (графики анализа)                        │
└─────────────────────────────────────────────────────────────┘
